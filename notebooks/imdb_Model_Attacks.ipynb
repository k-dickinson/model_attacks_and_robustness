{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install packages\n",
        "!pip install transformers textattack datasets --quiet\n",
        "\n",
        "# Imports\n",
        "import os, random, numpy as np, torch\n",
        "from copy import deepcopy\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from textattack.models.wrappers import HuggingFaceModelWrapper\n",
        "from textattack.datasets import HuggingFaceDataset\n",
        "from textattack import Attacker, AttackArgs\n",
        "\n",
        "# Import recipes - fixed import paths\n",
        "from textattack.attack_recipes import (\n",
        "    TextFoolerJin2019,\n",
        "    DeepWordBugGao2018,\n",
        "    PWWSRen2019,\n",
        "    BAEGarg2019,\n",
        ")\n",
        "\n",
        "# Set seed\n",
        "seed = 42\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on device:\", device)\n",
        "\n",
        "# Load & wrap model\n",
        "model_name = \"textattack/bert-base-uncased-imdb\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "wrapper = HuggingFaceModelWrapper(model, tokenizer)\n",
        "\n",
        "# Dataset - limit to smaller subset for testing\n",
        "dataset = HuggingFaceDataset(\"imdb\", split=\"test\")\n",
        "\n",
        "# Attack arguments\n",
        "base_args = AttackArgs(\n",
        "    num_examples=5,  # Reduced for faster testing\n",
        "    random_seed=seed,\n",
        "    shuffle=False,\n",
        "    disable_stdout=False,  # Enable to see progress\n",
        "    log_to_csv=None,\n",
        "    parallel=False  # Disable parallel processing to avoid issues\n",
        ")\n",
        "\n",
        "# Define attacks - fixed class references\n",
        "attacks = {\n",
        "    \"TextFooler\": TextFoolerJin2019.build(wrapper),\n",
        "    \"DeepWordBug\": DeepWordBugGao2018.build(wrapper),\n",
        "    \"PWWS\": PWWSRen2019.build(wrapper),\n",
        "    \"BAE\": BAEGarg2019.build(wrapper),\n",
        "}\n",
        "\n",
        "# Run attacks with error handling and CSV saving\n",
        "results = {}\n",
        "for name, attack in attacks.items():\n",
        "    print(f\"Running {name}...\")\n",
        "    try:\n",
        "        args = deepcopy(base_args)\n",
        "        # Set CSV filename for this attack\n",
        "        csv_filename = f\"{name.replace(' ', '_').replace('(', '').replace(')', '')}_results.csv\"\n",
        "        args.log_to_csv = csv_filename\n",
        "\n",
        "        attacker = Attacker(attack, dataset, args)\n",
        "        result = attacker.attack_dataset()\n",
        "        results[name] = result\n",
        "        print(f\"{name} completed successfully — results saved to {csv_filename}\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error running {name}: {str(e)}\")\n",
        "        print(f\"Skipping {name} and continuing...\\n\")\n",
        "        continue\n",
        "\n",
        "print(\"All attacks completed!\")\n",
        "print(\"Results summary:\")\n",
        "for name, result in results.items():\n",
        "    if result:\n",
        "        print(f\"{name}: {len(result)} examples processed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRPDcsSVvgth",
        "outputId": "c36f7660-d117-4d97-f1d7-bd6038606483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "textattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mimdb\u001b[0m, split \u001b[94mtest\u001b[0m.\n",
            "textattack: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\n",
            "textattack: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.01 and num_layers=1\n",
            "  warnings.warn(\n",
            "textattack: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n",
            "textattack: Logging to CSV at path CheckList_results.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running CheckList...\n",
            "Attack(\n",
            "  (search_method): GreedySearch\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  CompositeTransformation(\n",
            "    (0): WordSwapExtend\n",
            "    (1): WordSwapContract\n",
            "    (2): WordSwapChangeName\n",
            "    (3): WordSwapChangeNumber\n",
            "    (4): WordSwapChangeLocation\n",
            "    )\n",
            "  (constraints): \n",
            "    (0): RepeatModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-28 07:12:04,420 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:  20%|██        | 1/5 [00:17<01:10, 17.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 1 ---------------------------------------------\n",
            "[[Negative (100%)]] --> [[[FAILED]]]\n",
            "\n",
            "I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn't match the background, and painfully one-dimensional characters cannot be overcome with a 'sci-fi' setting. (I'm sure there are those of you out there who think Babylon 5 is good sci-fi TV. It's not. It's clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It's really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it's rubbish as they have to always say \"Gene Roddenberry's Earth...\" otherwise people would not continue watching. Roddenberry's ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 0 / 2 / 0 / 2:  40%|████      | 2/5 [00:27<00:41, 13.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 2 ---------------------------------------------\n",
            "[[Negative (100%)]] --> [[[FAILED]]]\n",
            "\n",
            "Worth the entertainment value of a rental, especially if you like action movies. This one features the usual car chases, fights with the great Van Damme kick style, shooting battles with the 40 shell load shotgun, and even terrorist style bombs. All of this is entertaining and competently handled but there is nothing that really blows you away if you've seen your share before.<br /><br />The plot is made interesting by the inclusion of a rabbit, which is clever but hardly profound. Many of the characters are heavily stereotyped -- the angry veterans, the terrified illegal aliens, the crooked cops, the indifferent feds, the bitchy tough lady station head, the crooked politician, the fat federale who looks like he was typecast as the Mexican in a Hollywood movie from the 1940s. All passably acted but again nothing special.<br /><br />I thought the main villains were pretty well done and fairly well acted. By the end of the movie you certainly knew who the good guys were and weren't. There was an emotional lift as the really bad ones got their just deserts. Very simplistic, but then you weren't expecting Hamlet, right? The only thing I found really annoying was the constant cuts to VDs daughter during the last fight scene.<br /><br />Not bad. Not good. Passable 4.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 0 / 3 / 0 / 3:  60%|██████    | 3/5 [00:32<00:21, 10.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 3 ---------------------------------------------\n",
            "[[Negative (100%)]] --> [[[FAILED]]]\n",
            "\n",
            "its a totally average film with a few semi-alright action sequences that make the plot seem a little better and remind the viewer of the classic van dam films. parts of the plot don't make sense and seem to be added in to use up time. the end plot is that of a very basic type that doesn't leave the viewer guessing and any twists are obvious from the beginning. the end scene with the flask backs don't make sense as they are added in and seem to have little relevance to the history of van dam's character. not really worth watching again, bit disappointed in the end production, even though it is apparent it was shot on a low budget certain shots and sections in the film are of poor directed quality\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 0 / 4 / 1 / 5: 100%|██████████| 5/5 [01:33<00:00, 18.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 4 ---------------------------------------------\n",
            "[[Negative (100%)]] --> [[[FAILED]]]\n",
            "\n",
            "STAR RATING: ***** Saturday Night **** Friday Night *** Friday Morning ** Sunday Night * Monday Morning <br /><br />Former New Orleans homicide cop Jack Robideaux (Jean Claude Van Damme) is re-assigned to Columbus, a small but violent town in Mexico to help the police there with their efforts to stop a major heroin smuggling operation into their town. The culprits turn out to be ex-military, lead by former commander Benjamin Meyers (Stephen Lord, otherwise known as Jase from East Enders) who is using a special method he learned in Afghanistan to fight off his opponents. But Jack has a more personal reason for taking him down, that draws the two men into an explosive final showdown where only one will walk away alive.<br /><br />After Until Death, Van Damme appeared to be on a high, showing he could make the best straight to video films in the action market. While that was a far more drama oriented film, with The Shepherd he has returned to the high-kicking, no brainer action that first made him famous and has sadly produced his worst film since Derailed. It's nowhere near as bad as that film, but what I said still stands.<br /><br />A dull, predictable film, with very little in the way of any exciting action. What little there is mainly consists of some limp fight scenes, trying to look cool and trendy with some cheap slo-mo/sped up effects added to them that sadly instead make them look more desperate. Being a Mexican set film, director Isaac Florentine has tried to give the film a Robert Rodriguez/Desperado sort of feel, but this only adds to the desperation.<br /><br />VD gives a particularly uninspired performance and given he's never been a Robert De Niro sort of actor, that can't be good. As the villain, Lord shouldn't expect to leave the beeb anytime soon. He gets little dialogue at the beginning as he struggles to muster an American accent but gets mysteriously better towards the end. All the supporting cast are equally bland, and do nothing to raise the films spirits at all.<br /><br />This is one shepherd that's strayed right from the flock. *\n",
            "\n",
            "\n",
            "--------------------------------------------- Result 5 ---------------------------------------------\n",
            "[[Positive (100%)]] --> [[[SKIPPED]]]\n",
            "\n",
            "First off let me say, If you haven't enjoyed a Van Damme movie since bloodsport, you probably will not like this movie. Most of these movies may not have the best plots or best actors but I enjoy these kinds of movies for what they are. This movie is much better than any of the movies the other action guys (Segal and Dolph) have thought about putting out the past few years. Van Damme is good in the movie, the movie is only worth watching to Van Damme fans. It is not as good as Wake of Death (which i highly recommend to anyone of likes Van Damme) or In hell but, in my opinion it's worth watching. It has the same type of feel to it as Nowhere to Run. Good fun stuff!\n",
            "\n",
            "\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 0      |\n",
            "| Number of failed attacks:     | 4      |\n",
            "| Number of skipped attacks:    | 1      |\n",
            "| Original accuracy:            | 80.0%  |\n",
            "| Accuracy under attack:        | 80.0%  |\n",
            "| Attack success rate:          | 0.0%   |\n",
            "| Average perturbed word %:     | nan%   |\n",
            "| Average num. words per input: | 215.6  |\n",
            "| Avg num queries:              | 191.25 |\n",
            "+-------------------------------+--------+"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.11/dist-packages/textattack/metrics/attack_metrics/words_perturbed.py:83: RuntimeWarning: Mean of empty slice.\n",
            "  average_perc_words_perturbed = self.perturbed_word_percentages.mean()\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "textattack: Logging to CSV at path Clare_T5-paraphrase_results.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CheckList completed successfully — results saved to CheckList_results.csv\n",
            "\n",
            "Running Clare (T5-paraphrase)...\n",
            "Attack(\n",
            "  (search_method): GreedySearch\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  CompositeTransformation(\n",
            "    (0): WordSwapMaskedLM(\n",
            "        (method):  bae\n",
            "        (masked_lm_name):  RobertaForCausalLM\n",
            "        (max_length):  512\n",
            "        (max_candidates):  50\n",
            "        (min_confidence):  0.0005\n",
            "      )\n",
            "    (1): WordInsertionMaskedLM(\n",
            "        (masked_lm_name):  RobertaForCausalLM\n",
            "        (max_length):  512\n",
            "        (max_candidates):  50\n",
            "        (min_confidence):  0.0\n",
            "      )\n",
            "    (2): WordMergeMaskedLM(\n",
            "        (masked_lm_name):  RobertaForCausalLM\n",
            "        (max_length):  512\n",
            "        (max_candidates):  50\n",
            "        (min_confidence):  0.005\n",
            "      )\n",
            "    )\n",
            "  (constraints): \n",
            "    (0): UniversalSentenceEncoder(\n",
            "        (metric):  cosine\n",
            "        (threshold):  0.7\n",
            "        (window_size):  15\n",
            "        (skip_text_shorter_than_window):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): RepeatModification\n",
            "    (2): StopwordModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [01:40<?, ?it/s]\n",
            "textattack: Logging to CSV at path Alzantot_results.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error running Clare (T5-paraphrase): 'upos'\n",
            "Skipping Clare (T5-paraphrase) and continuing...\n",
            "\n",
            "Running Alzantot...\n",
            "Attack(\n",
            "  (search_method): AlzantotGeneticAlgorithm(\n",
            "    (pop_size):  60\n",
            "    (max_iters):  40\n",
            "    (temp):  0.3\n",
            "    (give_up_if_no_improvement):  False\n",
            "    (post_crossover_check):  False\n",
            "    (max_crossover_retries):  20\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  8\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): MaxWordsPerturbed(\n",
            "        (max_percent):  0.2\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (max_mse_dist):  0.5\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): LearningToWriteLanguageModel(\n",
            "        (max_log_prob_diff):  5.0\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (3): RepeatModification\n",
            "    (4): StopwordModification\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 0 / 1 / 0 / 1:  20%|██        | 1/5 [19:53<1:19:35, 1193.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 1 ---------------------------------------------\n",
            "[[Negative (100%)]] --> [[[FAILED]]]\n",
            "\n",
            "I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn't match the background, and painfully one-dimensional characters cannot be overcome with a 'sci-fi' setting. (I'm sure there are those of you out there who think Babylon 5 is good sci-fi TV. It's not. It's clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It's really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it's rubbish as they have to always say \"Gene Roddenberry's Earth...\" otherwise people would not continue watching. Roddenberry's ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 1 / 1 / 0 / 2:  40%|████      | 2/5 [21:23<32:04, 641.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 2 ---------------------------------------------\n",
            "[[Negative (100%)]] --> [[Positive (67%)]]\n",
            "\n",
            "Worth the entertainment value of a rental, especially if you like action movies. This one features the usual car chases, fights with the great Van Damme kick style, shooting battles with the 40 shell load shotgun, and even terrorist style bombs. All of this is [[entertaining]] and competently handled but there is nothing that really blows you away if you've seen your share before.<br /><br />The plot is made interesting by the inclusion of a rabbit, which is clever but hardly profound. Many of the characters are [[heavily]] stereotyped -- the angry veterans, the terrified illegal aliens, the crooked cops, the indifferent feds, the bitchy [[tough]] lady station head, the crooked politician, the fat federale who looks like he was typecast as the Mexican in a Hollywood movie from the 1940s. All passably acted but again [[nothing]] special.<br /><br />I thought the main villains were pretty well done and fairly well acted. By the end of the movie you certainly knew who the good guys were and weren't. There was an emotional lift as the really bad ones got their just deserts. Very [[simplistic]], but then you weren't expecting Hamlet, right? The only thing I found really annoying was the constant cuts to VDs daughter during the last fight scene.<br /><br />Not bad. Not good. Passable 4.\n",
            "\n",
            "Worth the entertainment value of a rental, especially if you like action movies. This one features the usual car chases, fights with the great Van Damme kick style, shooting battles with the 40 shell load shotgun, and even terrorist style bombs. All of this is [[entertain]] and competently handled but there is nothing that really blows you away if you've seen your share before.<br /><br />The plot is made interesting by the inclusion of a rabbit, which is clever but hardly profound. Many of the characters are [[greatly]] stereotyped -- the angry veterans, the terrified illegal aliens, the crooked cops, the indifferent feds, the bitchy [[challenging]] lady station head, the crooked politician, the fat federale who looks like he was typecast as the Mexican in a Hollywood movie from the 1940s. All passably acted but again [[something]] special.<br /><br />I thought the main villains were pretty well done and fairly well acted. By the end of the movie you certainly knew who the good guys were and weren't. There was an emotional lift as the really bad ones got their just deserts. Very [[simple]], but then you weren't expecting Hamlet, right? The only thing I found really annoying was the constant cuts to VDs daughter during the last fight scene.<br /><br />Not bad. Not good. Passable 4.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 2 / 1 / 0 / 3:  60%|██████    | 3/5 [22:31<15:01, 450.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 3 ---------------------------------------------\n",
            "[[Negative (100%)]] --> [[Positive (77%)]]\n",
            "\n",
            "its a [[totally]] average film with a few semi-alright action sequences that make the plot seem a little better and remind the viewer of the classic van dam films. parts of the plot don't make sense and seem to be added in to use up time. the [[end]] plot is that of a very basic type that doesn't leave the viewer [[guessing]] and any twists are obvious from the beginning. the end scene with the [[flask]] backs don't make sense as they are added in and seem to have little relevance to the history of van dam's character. not [[really]] worth watching again, bit disappointed in the end production, even though it is apparent it was shot on a low budget certain shots and sections in the [[film]] are of poor directed quality\n",
            "\n",
            "its a [[absolutely]] average film with a few semi-alright action sequences that make the plot seem a little better and remind the viewer of the classic van dam films. parts of the plot don't make sense and seem to be added in to use up time. the [[ending]] plot is that of a very basic type that doesn't leave the viewer [[suppose]] and any twists are obvious from the beginning. the end scene with the [[balloon]] backs don't make sense as they are added in and seem to have little relevance to the history of van dam's character. not [[truly]] worth watching again, bit disappointed in the end production, even though it is apparent it was shot on a low budget certain shots and sections in the [[cinema]] are of poor directed quality\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 3 / 1 / 1 / 5: 100%|██████████| 5/5 [40:18<00:00, 483.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 4 ---------------------------------------------\n",
            "[[Negative (100%)]] --> [[Positive (93%)]]\n",
            "\n",
            "STAR RATING: ***** Saturday Night **** [[Friday]] Night *** Friday Morning ** Sunday Night * Monday Morning <br /><br />[[Former]] New Orleans homicide [[cop]] Jack Robideaux (Jean Claude Van Damme) is re-assigned to Columbus, a small but violent town in Mexico to help the police there with their efforts to stop a major [[heroin]] smuggling [[operation]] into their town. The [[culprits]] turn out to be ex-military, lead by former [[commander]] Benjamin Meyers (Stephen Lord, otherwise known as Jase from East Enders) who is using a special [[method]] he learned in Afghanistan to fight off his [[opponents]]. But Jack has a more personal reason for taking him down, that draws the two [[men]] into an explosive [[final]] showdown where only one will [[walk]] away [[alive]].<br /><br />After Until [[Death]], Van Damme appeared to be on a high, [[showing]] he [[could]] make the best straight to video [[films]] in the action market. [[While]] that was a far more drama oriented film, with The [[Shepherd]] he has returned to the high-kicking, no brainer [[action]] that first made him famous and has sadly produced his worst film since Derailed. It's nowhere near as [[bad]] as that film, but what I said [[still]] stands.<br /><br />A [[dull]], [[predictable]] film, with very little in the way of any [[exciting]] [[action]]. What little there is mainly consists of some limp fight scenes, trying to look cool and trendy with some cheap slo-mo/[[sped]] up [[effects]] added to them that [[sadly]] [[instead]] make them look more desperate. Being a Mexican set film, director Isaac Florentine has tried to give the film a Robert Rodriguez/Desperado sort of feel, but this only adds to the desperation.<br /><br />VD gives a [[particularly]] uninspired performance and given he's never been a Robert De [[Niro]] sort of actor, that can't be good. As the villain, [[Lord]] shouldn't expect to leave the beeb anytime soon. He gets little [[dialogue]] at the beginning as he struggles to muster an American [[accent]] but [[gets]] mysteriously [[better]] towards the end. All the supporting cast are [[equally]] [[bland]], and do [[nothing]] to raise the films spirits at all.<br /><br />This is one shepherd that's strayed right from the flock. *\n",
            "\n",
            "STAR RATING: ***** Saturday Night **** [[Yesterday]] Night *** Friday Morning ** Sunday Night * Monday Morning <br /><br />[[Ancient]] New Orleans homicide [[cops]] Jack Robideaux (Jean Claude Van Damme) is re-assigned to Columbus, a small but violent town in Mexico to help the police there with their efforts to stop a major [[hero]] smuggling [[function]] into their town. The [[criminals]] turn out to be ex-military, lead by former [[skipper]] Benjamin Meyers (Stephen Lord, otherwise known as Jase from East Enders) who is using a special [[mode]] he learned in Afghanistan to fight off his [[foes]]. But Jack has a more personal reason for taking him down, that draws the two [[man]] into an explosive [[definitive]] showdown where only one will [[walking]] away [[vivid]].<br /><br />After Until [[Fatality]], Van Damme appeared to be on a high, [[shows]] he [[did]] make the best straight to video [[film]] in the action market. [[Despite]] that was a far more drama oriented film, with The [[Berger]] he has returned to the high-kicking, no brainer [[initiatives]] that first made him famous and has sadly produced his worst film since Derailed. It's nowhere near as [[negative]] as that film, but what I said [[nonetheless]] stands.<br /><br />A [[boring]], [[foregone]] film, with very little in the way of any [[excite]] [[efforts]]. What little there is mainly consists of some limp fight scenes, trying to look cool and trendy with some cheap slo-mo/[[rushed]] up [[impacts]] added to them that [[unluckily]] [[however]] make them look more desperate. Being a Mexican set film, director Isaac Florentine has tried to give the film a Robert Rodriguez/Desperado sort of feel, but this only adds to the desperation.<br /><br />VD gives a [[specially]] uninspired performance and given he's never been a Robert De [[Nero]] sort of actor, that can't be good. As the villain, [[Senor]] shouldn't expect to leave the beeb anytime soon. He gets little [[discussions]] at the beginning as he struggles to muster an American [[focus]] but [[derives]] mysteriously [[improved]] towards the end. All the supporting cast are [[too]] [[tasteless]], and do [[something]] to raise the films spirits at all.<br /><br />This is one shepherd that's strayed right from the flock. *\n",
            "\n",
            "\n",
            "--------------------------------------------- Result 5 ---------------------------------------------\n",
            "[[Positive (100%)]] --> [[[SKIPPED]]]\n",
            "\n",
            "First off let me say, If you haven't enjoyed a Van Damme movie since bloodsport, you probably will not like this movie. Most of these movies may not have the best plots or best actors but I enjoy these kinds of movies for what they are. This movie is much better than any of the movies the other action guys (Segal and Dolph) have thought about putting out the past few years. Van Damme is good in the movie, the movie is only worth watching to Van Damme fans. It is not as good as Wake of Death (which i highly recommend to anyone of likes Van Damme) or In hell but, in my opinion it's worth watching. It has the same type of feel to it as Nowhere to Run. Good fun stuff!\n",
            "\n",
            "\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 3      |\n",
            "| Number of failed attacks:     | 1      |\n",
            "| Number of skipped attacks:    | 1      |\n",
            "| Original accuracy:            | 80.0%  |\n",
            "| Accuracy under attack:        | 20.0%  |\n",
            "| Attack success rate:          | 75.0%  |\n",
            "| Average perturbed word %:     | 5.96%  |\n",
            "| Average num. words per input: | 215.6  |\n",
            "| Avg num queries:              | 8340.0 |\n",
            "+-------------------------------+--------+\n",
            "Alzantot completed successfully — results saved to Alzantot_results.csv\n",
            "\n",
            "All attacks completed!\n",
            "Results summary:\n",
            "CheckList: 5 examples processed\n",
            "Alzantot: 5 examples processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List all CSV files in the current directory\n",
        "[file for file in os.listdir() if file.endswith(\".csv\")]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUHUEowm54gL",
        "outputId": "656f77a3-0f62-49a2-d8ab-00e3eaa07868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Alzantot_results.csv', 'CheckList_results.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('TextFooler_results.csv')\n",
        "files.download('DeepWordBug_results.csv')\n",
        "files.download('PWWS_results.csv')\n",
        "files.download('BAE_results.csv')"
      ],
      "metadata": {
        "id": "FWVarZ66k9Nf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4c218a40-878e-42de-8a0c-2a0f2d897570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d360afa8-5a44-4e73-83ad-2b27abae5887\", \"Alzantot_results.csv\", 13562)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f989d871-bd84-4e6b-a222-381cc37931ad\", \"CheckList_results.csv\", 13208)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select your csv files\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "QaftniBIVYqi",
        "outputId": "f7b74532-132e-4960-e06b-0f5f8dadde69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-89aed294-6109-4d01-9cbd-9d03d32417e5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-89aed294-6109-4d01-9cbd-9d03d32417e5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving BAE_results.csv to BAE_results.csv\n",
            "Saving DeepWordBug_results.csv to DeepWordBug_results.csv\n",
            "Saving PWWS_results.csv to PWWS_results.csv\n",
            "Saving TextFooler_results.csv to TextFooler_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q sentence-transformers transformers\n",
        "\n",
        "# Imports\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Load models\n",
        "semantic_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "gpt2_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "gpt2_model.eval()\n",
        "\n",
        "# Load CSVs\n",
        "textfooler = pd.read_csv(\"TextFooler_results.csv\")\n",
        "deepwordbug = pd.read_csv(\"DeepWordBug_results.csv\")\n",
        "pwws = pd.read_csv(\"PWWS_results.csv\")\n",
        "bae = pd.read_csv(\"BAE_results.csv\")\n",
        "\n",
        "methods = {\n",
        "    \"TextFooler\": textfooler,\n",
        "    \"DeepWordBug\": deepwordbug,\n",
        "    \"PWWS\": pwws,\n",
        "    \"BAE\": bae\n",
        "\n",
        "}\n",
        "\n",
        "# --- Metric Functions ---\n",
        "\n",
        "def success_rate(df):\n",
        "    df = df[df['result_type'] != 'Skipped']\n",
        "    return (df['result_type'] == 'Successful').mean()\n",
        "\n",
        "def avg_words_perturbed(df, result_type):\n",
        "    filtered = df[df['result_type'] != 'Skipped']\n",
        "    if result_type == 'Successful':\n",
        "        filtered = filtered[filtered['result_type'] == 'Successful']\n",
        "    elif result_type == 'Failed':\n",
        "        filtered = filtered[filtered['result_type'] != 'Successful']\n",
        "    counts = filtered['perturbed_text'].apply(lambda x: str(x).count('[['))\n",
        "    return counts.mean()\n",
        "\n",
        "def semantic_similarity(original_texts, perturbed_texts):\n",
        "    embeddings1 = semantic_model.encode(original_texts.tolist(), convert_to_tensor=True)\n",
        "    embeddings2 = semantic_model.encode(perturbed_texts.tolist(), convert_to_tensor=True)\n",
        "    similarities = util.cos_sim(embeddings1, embeddings2)\n",
        "    return similarities.diag().cpu().numpy().mean()\n",
        "\n",
        "def avg_fluency_score(texts):\n",
        "    scores = []\n",
        "    for t in texts:\n",
        "        encodings = gpt2_tokenizer(str(t), return_tensors='pt')\n",
        "        with torch.no_grad():\n",
        "            outputs = gpt2_model(**encodings, labels=encodings[\"input_ids\"])\n",
        "            log_likelihood = outputs.loss.item()\n",
        "            scores.append(-log_likelihood)  # Higher is better (less perplexity)\n",
        "    return sum(scores) / len(scores)\n",
        "\n",
        "# --- Final Output ---\n",
        "\n",
        "for name, df in methods.items():\n",
        "    df = df[df['result_type'] != 'Skipped']\n",
        "    success_df = df[df['result_type'] == 'Successful']\n",
        "    fail_df = df[df['result_type'] != 'Successful']\n",
        "\n",
        "    sr = success_rate(df) * 100\n",
        "    avg_success = avg_words_perturbed(df, 'Successful')\n",
        "    avg_fail = avg_words_perturbed(df, 'Failed')\n",
        "\n",
        "    if not success_df.empty:\n",
        "        sim_score = semantic_similarity(success_df['original_text'], success_df['perturbed_text'])\n",
        "        fluency_score = avg_fluency_score(success_df['perturbed_text'])\n",
        "    else:\n",
        "        sim_score = float('nan')\n",
        "        fluency_score = float('nan')\n",
        "\n",
        "    print(f\"{name} Success Rate: {sr:.2f}%\")\n",
        "    print(f\"{name} Avg. Words Perturbed (Successes): {avg_success:.2f}\")\n",
        "    print(f\"{name} Avg. Words Perturbed (Fails): {avg_fail:.2f}\")\n",
        "    print(f\"{name} Avg. Semantic Similarity (Successes): {sim_score:.3f}\")\n",
        "    print(f\"{name} Avg. Fluency Score (GPT-2) (Successes): {fluency_score:.2f}\")\n",
        "    print(\"---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-sonWDlDwux",
        "outputId": "4a3ce586-f4e6-4f6a-fc8d-d3d58116ccd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TextFooler Success Rate: 100.00%\n",
            "TextFooler Avg. Words Perturbed (Successes): 19.72\n",
            "TextFooler Avg. Words Perturbed (Fails): nan\n",
            "TextFooler Avg. Semantic Similarity (Successes): 0.951\n",
            "TextFooler Avg. Fluency Score (GPT-2) (Successes): -3.95\n",
            "---\n",
            "DeepWordBug Success Rate: 44.44%\n",
            "DeepWordBug Avg. Words Perturbed (Successes): 10.62\n",
            "DeepWordBug Avg. Words Perturbed (Fails): 25.00\n",
            "DeepWordBug Avg. Semantic Similarity (Successes): 0.931\n",
            "DeepWordBug Avg. Fluency Score (GPT-2) (Successes): -4.17\n",
            "---\n",
            "PWWS Success Rate: 100.00%\n",
            "PWWS Avg. Words Perturbed (Successes): 13.50\n",
            "PWWS Avg. Words Perturbed (Fails): nan\n",
            "PWWS Avg. Semantic Similarity (Successes): 0.958\n",
            "PWWS Avg. Fluency Score (GPT-2) (Successes): -3.90\n",
            "---\n",
            "BAE Success Rate: 72.22%\n",
            "BAE Avg. Words Perturbed (Successes): 8.00\n",
            "BAE Avg. Words Perturbed (Fails): 18.80\n",
            "BAE Avg. Semantic Similarity (Successes): 0.989\n",
            "BAE Avg. Fluency Score (GPT-2) (Successes): -3.86\n",
            "---\n"
          ]
        }
      ]
    }
  ]
}